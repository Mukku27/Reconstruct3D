# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eJlNbt7mGZeay01pEQ0m3kNXnqt0BryL

##Imports
"""

!pip install opencv-python numpy matplotlib open3d

"""### Preprocess Images
Load and preprocess the images to ensure they are in the correct format for further processing. This includes resizing and normalizing them.
"""

import cv2

# Load images
front_view = cv2.imread('/content/front.jpg')
side_view = cv2.imread('/content/side.jpg')
top_view = cv2.imread('/content/top.jpg')

# Resize images if necessary
height, width = 480, 640  # Example dimensions
front_view = cv2.resize(front_view, (width, height))
side_view = cv2.resize(side_view, (width, height))
top_view = cv2.resize(top_view, (width, height))

""" ### Estimate Depth Maps
 Use a depth estimation model to create depth maps from each of the images.
"""

def estimate_depth(image):
    import numpy as np
    import cv2

    # Convert to grayscale
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Apply GaussianBlur to reduce noise
    blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)

    # Use a Sobel filter to approximate gradients (edges can help infer depth)
    sobel_x = cv2.Sobel(blurred_image, cv2.CV_64F, 1, 0, ksize=5)
    sobel_y = cv2.Sobel(blurred_image, cv2.CV_64F, 0, 1, ksize=5)

    # Combine gradients to simulate depth intensity (simplistic approach)
    depth_map = np.sqrt(sobel_x**2 + sobel_y**2)


    # Normalize depth map to scale 0-255
    depth_map = cv2.normalize(depth_map, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)

    return depth_map

depth_front = estimate_depth(front_view)
depth_side = estimate_depth(side_view)
depth_top = estimate_depth(top_view)

"""###  Create Point Clouds
Convert the depth maps into point clouds. A point cloud is a collection of points in space representing the external surface of an object.

"""

import numpy as np
def create_point_cloud(image, depth_map):
    # Get image dimensions
    h, w = image.shape[:2]

    # Generate point cloud
    points = []
    for y in range(h):
        for x in range(w):
            z = depth_map[y, x]  # Depth value at pixel (x,y)
            if z > 0:  # Only consider points with valid depth values
                points.append([x, y, z])

    return np.array(points)

point_cloud_front = create_point_cloud(front_view, depth_front)
point_cloud_side = create_point_cloud(side_view, depth_side)
point_cloud_top = create_point_cloud(top_view,depth_top)

"""### Merge Point Clouds
 Combine the point clouds generated from each view into a single unified point cloud.
"""

combined_point_cloud = np.vstack((point_cloud_front, point_cloud_side, point_cloud_top))

""" ### Create 3D Mesh
Using Open3D or similar libraries, convert the combined point cloud into a mesh.
"""

import open3d as o3d

# Create Open3D PointCloud object
pcd = o3d.geometry.PointCloud()
pcd.points = o3d.utility.Vector3dVector(combined_point_cloud)

"""### Estimate normals and create mesh"""

pcd.estimate_normals()
mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd)

"""### Visualize the mesh"""

o3d.visualization.draw_geometries([mesh])

"""### Save the Model
Finally, save your generated 3D model in a suitable format (like .obj or .ply) for further use or analysis.

"""

o3d.io.write_triangle_mesh("output_model.ply", mesh)

"""# Conclusion

1.This workflow provides a basic framework for performing 3D reconstruction from three different views using Python.    
2.You may need to adapt certain parts based on specific requirements or enhancements like texture mapping or more sophisticated depth estimation techniques.





"""